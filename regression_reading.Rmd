---
title: "Reading Regression"
author: "mk4995"
date: "2024-12-15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Exploration

## Explore predictors.

Import data.

```{r}
source("scores_data.R")
```

Examine the overall data distributions and any correlations.
```{r}
scores_df |> select(-id) |> 
  gtsummary::tbl_summary() |> 
  gtsummary::bold_labels() |> 
  gtsummary::italicize_levels()

pairs(scores_df)
```

It appears that math score, reading score, and writing score are correlated pairwise.

## Decide if `reading_score` needs to be transformed.

```{r}
library(ggplot2)
library(dplyr)
library(patchwork)

scores_df |> 
  ggplot(aes(x = (reading_score))) +
  geom_boxplot()

scores_df |> 
  ggplot(aes(sample = (reading_score))) +
  geom_qq() + geom_qq_line()
```

According to the boxplot and QQ-plot above, `reading_score` does not meet the normality assumptions because of values in the higher range. We can try a Box Cox transformation to adjust this.

```{r}
library(caret)

# Create a Box-Cox transformation object
bc_transform <- BoxCoxTrans(scores_df$reading_score)  # Replace Area with your variable

# View the optimal lambda
bc_transform$lambda
```

According to the Box-Cox transformation, the ideal lambda is 1.3. Since 1.3 is difficult to contextualize in terms of score, let's try to compare this to 2. When we compare this to 2, we can see that the normality plot doesn't get much better - in fact, now the lower tails are worse. Based on this, for the ease of explanation, we will move forward with the original `reading_score` variable.

```{r}
scores_df |> 
  ggplot(aes(x = (reading_score)^2)) +
  geom_boxplot()

scores_df |> 
  ggplot(aes(sample = (reading_score)^2)) +
  geom_qq() + geom_qq_line()
```

# Building regression models

## Full model

We can start by creating a full model.

```{r}
reading_full_df = scores_df |> select(-c(id, math_score, writing_score))

reading_model = lm(reading_score ~ ., data = reading_full_df)
reading_model |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Full Model (no other scores) Coefficients")
```

Significant coefficients:

- (Intercept)
- gendermale
- ethnic_groupB
- ethnic_groupE
- lunch_typestandard
- test_prepcompleted
- parent_marital_statusmarried
- parent_educassociates degree
- parent_educbachelors degree
- parent_educmasters degree
- wkly_study_hours5-10

## Check spread of residuals.

**RSE = 13.2**: Indicates the average difference betweeen observeed and fitted values.

**R^2 = 0.2709**
About 26.09% of the variability in reading score is explained by the covariates.

**Adj-R^2 = 0.2425**
After penalizing for the predictors in the model that don't add anything useful, 21.82% of the variability in reading score is explained by the covariates.

## Plotting models

Looking at the plots below, we can see that the residuals generally follow normality, homoscedascity and mean zero looking at the diagnostic plots.

```{r}
par(mfrow=c(2,2))
plot(reading_model)
```

# Creating optimal models

Start regression procedures without the other score variables against `reading_score`.

In order to use these procedures, we must remove NAs from the dataset.
```{r}
# Does not contain id, math score, wrting score, or NAs
reading_df = scores_df |> na.omit() |> select(-c(id, math_score, writing_score))
```

Use forward and backward model selection and test-based procedures.

## Backward model
```{r}
# Backward model
mult.fit = lm(reading_score ~ ., data = reading_df)
summary(mult.fit)
backward_model = step(mult.fit, direction = "backward")

backward_model |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Backward Model Coefficients")
```

The resulting model is:

reading_score ~ gender + ethnic_group + parent_educ + lunch_type + test_prep + parent_marital_status + wkly_study_hours

The following coeffients from that model are significant:
- gendermale
- ethnic_groupE
- parent_educassociates degree
- parent_educbachelors degree
- parent_educmasters degree
- lunch_typestandard
- test_prepcompleted
- parent_marital_statusmarried
- wkly_study_hours5-10

## Forward model
```{r eval = FALSE}
# Forward model
null_model = lm(reading_score ~ 1, data = reading_df)
forward_model = step(null_model, direction = "forward", scope = formula(mult.fit))
forward_model |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Forward Model Coefficients (no other scores)")
```

The resulting model is: 

reading_score ~ lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours

The following coefficients from that model are significant:
- lunch_typestandard
- gendermale
- test_prepcompleted
- parent_educassociates degree
- parent_educbachelors degree
- parent_educmasters degree
- ethnic_groupE
- parent_marital_statusmarried
- wkly_study_hours5-10

# Interaction

## Run interaction plots.

One example here, rest are in code (not evaluated):

```{r}
# Ethnic Group
interaction.plot(
  x.factor = reading_df$lunch_type,
  trace.factor = reading_df$ethnic_group,
  response = reading_df$reading_score,
  col = rainbow(length(unique(reading_df$ethnic_group))),
  xlab = "Lunch Type",
  trace.label = "Ethnic Group",
  ylab = "Reading Score",
  main = "Interaction: Lunch Type x Ethnic Group"
)
```

```{r eval=FALSE}
# Define the combinations of x.factor and trace.factor
combinations <- list(
  list(x = "lunch_type", trace = "ethnic_group"),
  list(x = "parent_educ", trace = "ethnic_group"),
  list(x = "test_prep", trace = "ethnic_group"),
  list(x = "parent_marital_status", trace = "ethnic_group"),
  list(x = "practice_sport", trace = "ethnic_group"),
  list(x = "is_first_child", trace = "ethnic_group"),
  list(x = "nr_siblings", trace = "ethnic_group"),
  list(x = "transport_means", trace = "ethnic_group"),
  list(x = "wkly_study_hours", trace = "ethnic_group"),
  list(x = "lunch_type", trace = "parent_educ"),
  list(x = "test_prep", trace = "parent_educ"),
  list(x = "parent_marital_status", trace = "parent_educ"),
  list(x = "practice_sport", trace = "parent_educ"),
  list(x = "is_first_child", trace = "parent_educ"),
  list(x = "nr_siblings", trace = "parent_educ"),
  list(x = "transport_means", trace = "parent_educ"),
  list(x = "wkly_study_hours", trace = "parent_educ"),
  list(x = "practice_sport", trace = "parent_marital_status"),
  list(x = "nr_siblings", trace = "parent_marital_status"),
  list(x = "transport_means", trace = "parent_marital_status"),
  list(x = "wkly_study_hours", trace = "parent_marital_status"),
  list(x = "is_first_child", trace = "practice_sport"),
  list(x = "nr_siblings", trace = "practice_sport"),
  list(x = "transport_means", trace = "practice_sport"),
  list(x = "wkly_study_hours", trace = "practice_sport"),
  list(x = "nr_siblings", trace = "is_first_child"),
  list(x = "wkly_study_hours", trace = "is_first_child"),
  list(x = "wkly_study_hours", trace = "transport_means")
)

library(gridExtra)

# Function to create and capture an interaction plot as a grob
create_interaction_plot <- function(x, trace, response, data) {
  interaction.plot(
    x.factor = data[[x]],
    trace.factor = data[[trace]],
    response = data[[response]],
    col = rainbow(length(unique(data[[trace]]))),
    xlab = x,
    trace.label = trace,
    ylab = response,
    main = paste("Interaction:", x, "x", trace)
  )
}

# Generate and store all interaction plots
interaction_plots <- lapply(combinations, function(combo) {
  create_interaction_plot(combo$x, combo$trace, "reading_score", reading_df)
})

```

### Potential interactions (as found from plots):
- Lunch Type x Ethnic Group
- Parent Educ x Ethnic Group
- Test Prep x Ethnic Group
- Parent Marital Status x Ethnic Group
- Practice Sport x Ethnic Group
- Is First Child x Ethnic Group
- Number of Siblings x Ethnic Group
- Transport Means x Ethnic Group
- Weekly Study Hours x Ethnic Group
- Lunch Type x Parent Educ
- Test Prep x Parent Educ
- Parent Marital Status x Parent Educ
- Practice Sport x Parent Educ
- Is First Child x Parent Educ
- Number of Siblings x Parent Educ
- Transport Means x Parent Educ
- Weekly Study Hours x Parent Educ
- Practice Sport x Parent Marital Status
- Number of Siblings x Parent Marital Status
- Transport Means x Parent Marital Status
- Weekly Study Hours x Parent Marital Status
- Is First Child x Practice Sport
- Number of Siblings x Practice Sport
- Transport Means x Practice Sport
- Weekly Study Hours x Practice Sport
- Number of Siblings x Is First Child
- Weekly Study Hours x Is First Child
- Weekly Study Hours x Transport Means

## Running models with significant interactions

All of the variables above had plots that indicated there may be a chance of interaction. Let's try fitting a full model again with these possible interactions to see what's significant. The final FULL model is below with significant interaction terms:

```{r}
full_with_interactions = lm(reading_score ~ . + parent_educ*wkly_study_hours + parent_marital_status*wkly_study_hours, data = reading_df)

full_with_interactions |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Full model coefficients with significant interaction terms")
```

Significant coefficients from the full model with interactions:
- gendermale
- ethnic_groupE
- lunch_typestandard
- test_prepcompleted
- parent_educbachelors degree:wkly_study_hours5-10
- parent_marital_statussingle:wkly_study_hours> 10

Use an automatic procedure to refit the model based on the significant interactions we found above.
```{r}
# Add an interaction term and refit the model

interactions_null = lm(reading_score ~ 1, data = reading_df)
interaction_best_model = step(interactions_null, direction = "forward", scope = formula(full_with_interactions))

full_with_interactions |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Forward model coefficients with significant interaction term")
```

Significant coefficients from this model (including interactions):
- lunch_typestandard
- gendermale
- test_prepcompleted
- parent_educassociates degree
- parent_educbachelors degree
- parent_educmasters degree
- ethnic_groupE
- parent_marital_statussingle:wkly_study_hours> 10

# Examining the Residuals (without other scores)
Let's take a look at the residuals to make sure assumptions are met for the most recent model, since it has the best adjusted R^2 and RMSE so far (in table below).

```{r}
par(mfrow=c(2,2))
plot(interaction_best_model)
```

The normality assumptions are met for the most part, but it looks like 34 is an outlier. Let's try running the model again without that outlier.

```{r}
filtered_reading <- reading_df %>% filter(row_number() != 34)
filtered_full = lm(reading_score ~ . + parent_educ*wkly_study_hours + parent_marital_status*wkly_study_hours, data = filtered_reading)
filtered_interactions_null = lm(reading_score ~ 1, data = filtered_reading)
filtered_best = step(filtered_interactions_null, direction = "forward", scope = formula(full_with_interactions))

par(mfrow=c(2,2))
plot(filtered_best)
```

After removing the outlier, our residuals vs. leverage plot looks much better, and the other plots are still consistent. This model is now better suited to meet regression assumptions.

# Choosing the Final Reading Model

|Model (without other scores) |R^2            |Adjusted R^2       |RMSE          |
|-------------------------------|---------------|------------------|---------------|
|**Full model**: reading_score ~ lunch_type + gender + test_prep + ethnic_group + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_mean + wkly_study_hours   |0.2709     |0.2425   |13.2    |
|**Forward model**: reading_score ~ lunch_type + gender + test_prep + ethnic_group + parent_marital_status + is_first_child    |0.2661   |0.2442   |13.19    |
|**Backward model**: reading_score ~ gender + ethnic_group + lunch_type + test_prep + parent_marital_status + is_first_child |0.2661    |0.2442   |13.19   |
|**Full model with interactions**: reading_score ~ lunch_type + gender + test_prep + ethnic_group + parent_marital_status + practice_sport + is_first_child + nr_siblings + transport_mean + wkly_study_hours +  parent_educ:wkly_study_hours + parent_marital_status:wkly_study_hours    |0.303     |0.2547   |13.09    |
|**Forward model with interactions**: reading_score ~ lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours + parent_marital_status:wkly_study_hours    |0.2827   |0.2534    |13.11    |
|***Forward model with interactions and without outlier***: reading_score ~ lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours + parent_marital_status:wkly_study_hours    |0.2846   |0.2553    |12.96    |

Based on these results, we believe that the last model in the table performs the best, given that it has the highest adjusted R^2 value and lowest RMSE. The model also meets the regression assumptions - though it may be useful to consider other influential observations! The data here shows that the variability accounted for by the linear relationship between the predictors and the outcome is 0.2846, and the addition of a new useful predictor accounts for 0.2553 of the variability. 

Thus, our final model is:

**reading_score ~ lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours + parent_marital_status * wkly_study_hours**

```{r echo=FALSE}
filtered_best |> summary() |> broom::tidy() |> knitr::kable(digits = 10, caption = "Final Model Coefficients: Forward selection model with interactions and without outlier")
```


# Cross Validation

We can also perform cross validation to assess the performance of our model.

```{r}
# Use 10-fold validation and create the training sets
train = trainControl(method = "cv", number = 5)

# Fit the filtered_best model
reading_model = train(
  reading_score ~ lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours + parent_marital_status*wkly_study_hours,
  data = filtered_reading,
  trControl = train,
  method = 'lm')

reading_model$results |> knitr::kable()
```

On average, the reading model explains 23.7% of the score's variance. The RMSE is 13.17, and the model has an average absolute difference of 10.72 between the true and predicted values.

# With Other Scores

We can now also assess how adding other scores (math and writing) to the model will affect its performance.

```{r}
reading_and_scores = scores_df |> select(-id) |> na.omit()
reading_and_scores = reading_and_scores |> filter(row_number() != 34)

reading_with_other_scores = lm(reading_score ~ math_score + writing_score + lunch_type + gender + test_prep + parent_educ + ethnic_group + parent_marital_status + wkly_study_hours + parent_marital_status*wkly_study_hours, data = reading_and_scores)

mse_reading_scores = mean((reading_and_scores$reading_score - predict(reading_with_other_scores, newdata = reading_and_scores))^2)

mse_reading = mean((reading_and_scores$reading_score - predict(filtered_best, newdata = reading_and_scores))^2)

tibble(
  model = c("Reading with scores", "Reading without scores"),
  MSE = c(mse_reading_scores, mse_reading)
) |> knitr::kable()
```

The MSE decreased by a tenfold after adding other scores to the model. Therefore, we can conclude the writing and math scores can have a significant effect on the reading score, and can leverage that in building another model.
